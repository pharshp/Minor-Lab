# -*- coding: utf-8 -*-
"""TAI LAB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tTPMSmM65-DyNq_4oQ1qOEgabuBZ_CNg
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt

transform = transforms.Compose([
    transforms.ToTensor(),
])
test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout(0.25)
        self.dropout2 = nn.Dropout(0.5)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output

try:
    model = Net()
    model.load_state_dict(torch.load('mnist_cnn.pt'))
except FileNotFoundError:
    print("Pre-trained model not found. Training a new model...")
    model = Net()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('./data', train=True, download=True, transform=transform),
        batch_size=64, shuffle=True)
    model.train()
    for epoch in range(1):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = F.nll_loss(output, target)
            loss.backward()
            optimizer.step()
            if batch_idx > 50:
                break
    torch.save(model.state_dict(), 'mnist_cnn.pt')
    print("Model trained and saved as mnist_cnn.pt")

model.eval()

correctly_classified_images = []
for image, label in test_loader:
    output = model(image)
    pred = output.max(1, keepdim=True)[1]
    if pred.item() == label.item():
        correctly_classified_images.append((image, label))
    if len(correctly_classified_images) >= 100:
        break

loss_fn = nn.CrossEntropyLoss()

def get_prediction_and_loss(model, image, label):
    output = model(image)
    loss = loss_fn(output, label)
    pred = output.max(1, keepdim=True)[1]
    return pred, loss


def untargeted_fgsm_attack(image, epsilon, true_label, model):
    image.requires_grad = True
    output = model(image)
    loss = loss_fn(output, true_label)
    model.zero_grad()
    loss.backward()
    gradient = image.grad.data
    perturbed_image = image + epsilon * torch.sign(gradient)
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image

epsilons = [0.01, 0.05, 0.1, 0.2]

for epsilon in epsilons:
    misclassified_count = 0
    total_l_inf_norm = 0

    for image, true_label in correctly_classified_images:
        perturbed_image = untargeted_fgsm_attack(image.clone(), epsilon, true_label, model)
        pred_after_attack, _ = get_prediction_and_loss(model, perturbed_image, true_label)

        if pred_after_attack.item() != true_label.item():
            misclassified_count += 1

        perturbation = perturbed_image - image
        l_inf_norm = torch.max(torch.abs(perturbation)).item()
        total_l_inf_norm += l_inf_norm

    success_rate = (misclassified_count / len(correctly_classified_images)) * 100
    avg_l_inf_norm = total_l_inf_norm / len(correctly_classified_images)

    print(f"Epsilon: {epsilon}")
    print(f"  Success Rate: {success_rate:.2f}%")
    print(f"  Average L-infinity norm: {avg_l_inf_norm:.4f}\n")


num_visualizations = 5
epsilon_for_viz = 0.1

fig, axes = plt.subplots(num_visualizations, 3, figsize=(9, 15))
fig.suptitle(f'FGSM Attack with Epsilon = {epsilon_for_viz}', fontsize=16)

for i in range(num_visualizations):
    image, true_label = correctly_classified_images[i]

    pred_before, _ = get_prediction_and_loss(model, image, true_label)
    axes[i, 0].imshow(image.squeeze().detach().numpy(), cmap='gray')
    axes[i, 0].set_title(f"Original\nPred: {pred_before.item()}")
    axes[i, 0].axis('off')

    perturbed_image = untargeted_fgsm_attack(image.clone(), epsilon_for_viz, true_label, model)
    pred_after, _ = get_prediction_and_loss(model, perturbed_image, true_label)
    axes[i, 1].imshow(perturbed_image.squeeze().detach().numpy(), cmap='gray')
    axes[i, 1].set_title(f"Adversarial\nPred: {pred_after.item()}")
    axes[i, 1].axis('off')

    perturbation = perturbed_image - image
    amplified_perturbation = torch.clamp(perturbation * 10 + 0.5, 0, 1)
    axes[i, 2].imshow(amplified_perturbation.squeeze().detach().numpy(), cmap='gray')
    axes[i, 2].set_title("Perturbation\n(amplified)")
    axes[i, 2].axis('off')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()